{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254bb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain import ConversationChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import os\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f65800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "    loader = DirectoryLoader(\"./Guide_Directory\", glob = \"*.txt\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    #splitting the text into\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "    \n",
    "    #OpenAI Embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = Chroma.from_documents(texts, embeddings)\n",
    "    \n",
    "    #llm\n",
    "    llm = OpenAI(temperature = 0.9, verbose = False, model_name = 'gpt-3.5-turbo')\n",
    "    \n",
    "    #Retrieval chains\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    retriever = docsearch.as_retriever()\n",
    "    \n",
    "    conversation = ConversationalRetrievalChain.from_llm(llm = llm,retriever = retriever, memory = memory, verbose = True)\n",
    "    \n",
    "    answer = conversation({\"question\":query})['answer']\n",
    "    print(conversation)\n",
    "    \n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca07b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app. \n",
      "\n",
      "Also please ensure that your antivirus or firewall is not blocking the binary file located at: C:\\Users\\pragn\\anaconda3\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pragn\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:189: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\pragn\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:769: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "HEALTH\n",
      "\n",
      "of things and respond to them. How you think about your situation impacts how you feel. Recognize that negative thoughts are just that, thoughts that can be acknowledged and set aside. Accept change. Being able to accept change is a part of life. There may be some things that get in the way of your goals. It is ok to accept some things. Focus instead on the things that are in your power to change and control. Maintain a hopeful outlook. It is not realistic to be positive all the time. Allow yourself to feel upset for a little bit, but then focus on what gives you hope. What do you want and how can you make that happen? Learn from your past.\n",
      "\n",
      "of things and respond to them. How you think about your situation impacts how you feel. Recognize that negative thoughts are just that, thoughts that can be acknowledged and set aside. Accept change. Being able to accept change is a part of life. There may be some things that get in the way of your goals. It is ok to accept some things. Focus instead on the things that are in your power to change and control. Maintain a hopeful outlook. It is not realistic to be positive all the time. Allow yourself to feel upset for a little bit, but then focus on what gives you hope. What do you want and how can you make that happen? Learn from your past.\n",
      "\n",
      "Trauma and Mental Health\n",
      "\n",
      "Question: Hello How are you?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hello How are you?', additional_kwargs={}, example=False), AIMessage(content=\"I'm an AI language model, so I don't have feelings, but thank you for asking! How can I assist you today?\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history') callbacks=None callback_manager=None verbose=False tags=None combine_docs_chain=StuffDocumentsChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), llm=OpenAIChat(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.9}, openai_api_key=None, openai_api_base=None, openai_proxy=None, max_retries=6, prefix_messages=[], streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n') question_generator=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, prompt=PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True), llm=OpenAIChat(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.9}, openai_api_key=None, openai_api_base=None, openai_proxy=None, max_retries=6, prefix_messages=[], streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}) output_key='answer' return_source_documents=False return_generated_question=False get_chat_history=None retriever=VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x00000146CD6D0F40>, search_type='similarity', search_kwargs={}) max_tokens_limit=None\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "They will help keep you safe. 2. Wear a mask when you are around large groups of people, especially indoors. 3. Pay attention to infection levels. If a lot of people are getting sick, it’s good to be more cautious. 4. Isolate if you are sick or have been around someone who is sick. 5. Wash your hands often. If you get sick COVID-19 can look like a lot of different illnesses. The most common symptoms are fever, cough, and shortness of breath. You might feel tired or achy. You might vomit or have diarrhea. Some people show no symptoms while others become very sick and end up in the hospital on a ventilator. If you have mild symptoms, you can treat the virus at home. Rest, drink plenty of water, take acetaminophen (Tylenol) for fever, drink a warm tea with honey for a cough, and stay away from others as much as possible while contagious.\n",
      "\n",
      "Emergency Warning Signs Do you have trouble breathing, pain or pressure in the chest, or confusion? Are you too sleepy for someone to wake you? Go to a hospital emergency room right away or call 9-1-1. If you’re not sure if you should go, call your health provider or a health clinic. COVID testing. You can order free at-home COVID-19 tests at covidtests.gov. It’s a good idea to have a few tests on hand. If you think you might have COVID, call 2-1-1. No-cost testing is available nationwide at health centers and select pharmacies.\n",
      "\n",
      "“Go to a community medical center. You can get a free full physical when you get out of prison. We have to make sure there are no underlying conditions that we aren’t aware of.” —Joe Joe\n",
      "\n",
      "Major depressive disorder. Everyone feels sad once in a while, but not everyone feels depressed. Symptoms include: • Feeling sad or uninterested in things most of the time. • Changes in eating and sleeping habits. • Having low energy and/or a hard time focusing. • Feeling tearful, empty, or hopeless. • Feeling angry and irritable. • Feeling miserable but not understanding why. • Having chronic pain, headaches, fatigue, or digestive issues. Do these symptoms last for at least two weeks? Do they get in the way of your everyday life? You may be depressed. Talk therapy or medicine can help. If you are severely depressed, you may also have thoughts of wanting to hurt yourself or die (this is a big concern for women who are recently released). Severe depression may also cause you to hear or see things that are not there. If you have these severe symptoms, go to the nearest emergency room right away or call the suicide and crisis lifeline: 988. Bipolar disorder. Most people have changes in\n",
      "\n",
      "so that you know if you need to seek help. Generalized anxiety disorder. Feeling anxious or stressed once in a while is a normal part of life. If your anxiety feels out of control, you might have an anxiety disorder. Generalized anxiety disorder is when you worry a lot and are nervous about everyday things, even things that you have no control over, for no apparent reason. You might feel like something really bad is going to happen. Anxiety leaves you feeling restless, tired, irritable, and tense. It can impact your ability to focus and sleep. If these problems do not go away and begin to impact your relationships and responsibilities, get help. Talk therapy can help.\n",
      "\n",
      "Question: I have some cough symptoms and I'm feeling tired. What should I do?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content=\"I have some cough symptoms and I'm feeling tired. What should I do?\", additional_kwargs={}, example=False), AIMessage(content='Based on the provided information, if you have cough symptoms and are feeling tired, it is possible that you may have COVID-19. In this case, it is recommended to treat the virus at home by resting, drinking plenty of water, taking acetaminophen (Tylenol) for fever, and drinking warm tea with honey for a cough. It is also important to stay away from others as much as possible while contagious. However, if you experience trouble breathing, pain or pressure in the chest, confusion, or excessive sleepiness, it is advised to go to a hospital emergency room right away or call 9-1-1. If you are unsure, you can also call your health provider or a health clinic for guidance.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history') callbacks=None callback_manager=None verbose=False tags=None combine_docs_chain=StuffDocumentsChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), llm=OpenAIChat(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.9}, openai_api_key=None, openai_api_base=None, openai_proxy=None, max_retries=6, prefix_messages=[], streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n') question_generator=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, prompt=PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True), llm=OpenAIChat(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.9}, openai_api_key=None, openai_api_base=None, openai_proxy=None, max_retries=6, prefix_messages=[], streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}) output_key='answer' return_source_documents=False return_generated_question=False get_chat_history=None retriever=VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x00000146D0FB10D0>, search_type='similarity', search_kwargs={}) max_tokens_limit=None\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatbot(input, history=[]):\n",
    "    output = answer_query(input)\n",
    "    history.append((input, output))\n",
    "    return history, history\n",
    "\n",
    "gr.Interface(fn = chatbot,\n",
    "             inputs = [\"text\",'state'],\n",
    "             outputs = [\"chatbot\",'state'],\n",
    "             title = \"Your friendly neighbourhood chatbot :)\",\n",
    "             description=\"Disclaimer: This is not the final product. This is not even the initial product. This is just for your reference.\").launch(debug = False, share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60c1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app. \n",
      "\n",
      "Also please ensure that your antivirus or firewall is not blocking the binary file located at: C:\\Users\\pragn\\anaconda3\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic one\n",
    "demo = gradio.Interface(fn=answer_query,\n",
    "                        inputs = gradio.Textbox(lines=2, label = \"Hi there! How can I help you today?\", placeholder=\"Type your query here\"),\n",
    "                        outputs = \"text\",\n",
    "                        title = \"Your friendly neighborhood chatbot:)\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
